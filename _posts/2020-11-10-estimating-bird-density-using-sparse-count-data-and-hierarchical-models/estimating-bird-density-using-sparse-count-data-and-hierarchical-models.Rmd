---
title: "Estimating bird density using sparse count data and hierarchical models"
description: |
author:
  - name: John Yeiser
    url: https://johnyeiser.wixsite.com/main
date: 11-02-2020
output:
  distill::distill_article:
    self_contained: false
bibliography: bibtex/website.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
The following is a brief companion piece to "Addressing Temporal Variability in Bird Calling with Design and Estimation: A Northern Bobwhite Example"[@Yeiser2020bJWM].

### Context

Biologists and managers spend a lot of their time monitoring wildlife to understand how many individuals are in a particular area. This is important to know because accurate and precise estimates of density can inform conservation policies, land management decisions, and harvest regulations. For birds, a common approach to estimating density is to fit statistical models to counts that have auxillary data like *distance-to-observer*, which helps us estimate the probability that birds are detected.

Natural resource management agencies spend a considerable amount of time monitoring northern bobwhite. They are declining throughout their range and are subject to local extirpation if isolated from other populations, but in many places they are abundant enough to be hunted. Bobwhite are ecologically, economically, and socially valueable. Getting reliable density estimates is paramount to harvesting populations sustainably while satisfying stakeholders. Unfortunately, during autumn when density estimates would be most informative to setting harvest regulations, bobwhites are not easy to survey. 

```{r fig.cap="The range wide decline in northern bobwhite according to Breeding Bird Surveys. Data from: https://www.pwrc.usgs.gov/bbs/"}
knitr::include_graphics("bobwhite-decline.png")
```

There are a host of reasons why it's difficult to get an idea of bobwhite density in autumn: only a small fraction of the population vocalizes, observer detection rate is less than 1, calling rate is less than 1, and the logistics are challenging (it's only possible to do one survey per point per day). All of these issues can lead to low numbers of detections, which can make it difficult to use statistical models to estimate density. Because of these issues, managers often use *correction factors*, or estimates of the detection process from another system, to calculate density. 

An issue with using fixed correction factors is that calling rate in bobwhite varies among geographies, annually, and within one sampling season. Any  one correction factor, even if it's based on realistic estimates, is probably unlikely to represent the detection process of a different geography in any one year. Also, if we use correction factors we have no way of knowing the uncertainty around our estimates -- it's no better than an educated guess!

Me, James Martin, Paige Howell, and Greg Wann were interested in understanding the potential bias associated with correction factors in systems where detection processes vary over time. Is it worth collecting data if you're just going to use an educated guess each year? But, can we even apply statistical models to these data given the information is usually sparse?

### Main Objectives

We used a simulation approach to determine the bias and precision of northern bobwhite densities estimated via:

1. A fully-specified, advanced hierarchical distance sampling model
2. Mis-specified distance sampling models
3. Correction factors

When you simulate a population process or observation process, you know what the answer should be (because you use that information to build the simulation). Because we know the answers, we can calculate the bias and precision of each approach. 

### Approach

We simulated a 0.25 bird/acre bobwhite populations within a fictitious ~25,000 acre area (assuming 11 bird coveys) and randomly selected a realistic number of distance sampling point count locations (35). We simulated the sampling process for 5 years with 3 visits per year and allowed for random variation in the detection process among years and visits. We used existing literature and our experience with monitoring to set a range of detection rates and calling rates typical for bobwhite populations. We allowed populations to grow by 5% each year. 


```{r layout = 'l-body', preview=TRUE, fig.cap="An example of a 0.25 bird/acre bobwhite population in a fictitious 25,000 acre area. The number of coveys detected in any one sampling visit depends on sampling effort, detection probability, and calling rate. In this example, about 29% of the area is being sampled. In one visit, 49 out of the 138 coveys present in sampling points were detected."}
knitr::include_graphics("BobwhiteSamplingSim.png")
```


We then fit models or applied correction factors to those counts to estimate density and population growth rate. We repeated this simulation several hundred times and looked at the distribution of bias and precision across all simulations. We also altered the number of sampling points (35 or 70), sampling visits per year (3 vs 1), and sampling years (5 or 10) to see how that influenced model accuracy. 

### Results

The fully-specified model fit to 3 sampling visits did a pretty good job of estimating variation in calling rate, which is an important aspect of modeling bobwhite populations. 

```{r layout = 'l-body', fig.cap="The simulated relationship between date and calling rate (probability of availability) in bobwhites (solid line) and estimated relationship from the fully-specified model (dashed line). The polygons represent the 95% quantile for the generating data (i.e., annual variation, dark polygon) and 95% credibility intervals of the estimated relationship (light polygon) "}
knitr::include_graphics("Figure1.png")
```

The density estimates from the fully-specified model was relatively unbiased and precise compared to correction factors and other mis-specified models. On average across all simulations, some correction factors weren't too biased. This makes sense because the numbers we used to inform our simlation are similar to those used in correction factors. That is, the correction factors are based in reality and so is our simulation, so it's not surprising that *on average*, bias isn't bad. However, in any given year, the correction factors had much higher variability in bias than modeled estimates. 

One of the most important outcomes was that compared to using correction factors, as you collected more data you got more precise estimates and a better idea of population trends when you used correctly specified statistical models (or any statistical model that we considered, for that matter). 

```{r layout = 'l-body', fig.cap="Estimates of population growth from statistical models (Scenario 1-3) are much more precise than that of correction factors (Scenarios 4 and 5), especially as more data is collected."}
knitr::include_graphics("Figure3.png")
```

### The take-home message

We demonstrated that you can use advanced hierarchical distance sampling models on typical bobwhite data sets to get relatively unbiased and precise estimates of density and population change. This is the best way to get a return on your considerable investment of monitoring bobwhite in the fall, which is no easy task. We strongly advise against using correction factors, which have unpredictable bias and over time do not improve your ability to detect population trends.



